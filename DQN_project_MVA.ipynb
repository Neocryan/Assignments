{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQQogKhnrNZK"
   },
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lsYZsxQyrNZS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\env\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsjnPGg1rNaA"
   },
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xH9l4MS4rNaK"
   },
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vv3O6AOZrNaQ"
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O97mRlahrNaa"
   },
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQmC5QrSrNai"
   },
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHqj3adbrNau"
   },
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOB_ox5xrNa4"
   },
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dHe2tTVTrNa-"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQmrXQj5rNba"
   },
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydc3ZYKzrNbe"
   },
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUKC1QZzrNbm"
   },
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z4TIkqfBrNbo"
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLHZZ1R4rNb8"
   },
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbgzJcQGrNcC"
   },
   "source": [
    "The agent has to exploit what it has already experienced in order to obtain reward, but it also has to explore in order to make better action selections in the future. The dilemma is that neither exploration nor exploitation can be pursued exclusively without failing at the task. The agent must try a variety of actions and progressively favor those that appear to be best.\n",
    "\n",
    "The $\\epsilon$ made the agent continued to explore and to improve their chances of recognizing the optimal action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2xCGksBrNcG"
   },
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjL11RxXrNcM"
   },
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xM0__Ha8rNca"
   },
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0PgTWJGrNce"
   },
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0wv7GkQDrNcm"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        if np.count_nonzero(self.board == 0.5) == 0:\n",
    "          reward += 5\n",
    "          game_over = True\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8DLILXHorNc0"
   },
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "APUEVVZUrNc2"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=101 # set small when debugging\n",
    "epochs_test=11 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5T5OkP1rNdK"
   },
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHEugxkqrNdM"
   },
   "source": [
    "The position and board embed the pairs of coordinates to a fixed size of array, shape of (5,5,2) for example. In this way, the agent can capture more information from the environment, more importantly, the agent can use a CNN network to capture the information of channels in the environment. And the gradient will converge faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTskXQ2erNdO"
   },
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdR0ufTirNda"
   },
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2Hq8Q7abrNdi"
   },
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        \n",
    "        return np.random.choice([0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoulXH8wrNd-"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qjl3OUYWrNeK"
   },
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        ##### FILL IN HERE\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "        # The agent performs an action\n",
    "            action = agent.learned_act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over ,com= env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "            # Update stats\n",
    "        score = score + win-lose\n",
    "            \n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('\\nFinal score: '+str(score/epochs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11351,
     "status": "ok",
     "timestamp": 1523447225969,
     "user": {
      "displayName": "Ryan Tian",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103527607988458266637"
     },
     "user_tz": -120
    },
    "id": "ZpBgoLE3rNei",
    "outputId": "39eac15b-fe54-4435-b1aa-695ba782de08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 11.0/16.0. Average score (-5.0)\n",
      "Win/lose count 8.5/22.0. Average score (-9.25)\n",
      "Win/lose count 9.0/12.0. Average score (-7.166666666666667)\n",
      "Win/lose count 14.0/14.0. Average score (-5.375)\n",
      "Win/lose count 9.0/11.0. Average score (-4.7)\n",
      "Win/lose count 4.5/7.0. Average score (-4.333333333333333)\n",
      "Win/lose count 9.0/15.0. Average score (-4.571428571428571)\n",
      "Win/lose count 8.0/15.0. Average score (-4.875)\n",
      "Win/lose count 8.0/12.0. Average score (-4.777777777777778)\n",
      "Win/lose count 5.5/6.0. Average score (-4.35)\n",
      "\n",
      "Final score: -4.35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,10,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QolACq9IrNey"
   },
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtLslOZcrNe0"
   },
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZplIOXPrNe4"
   },
   "source": [
    "__1__\n",
    "\\begin{split}\n",
    "Q^\\pi (s,a) &= \\mathbb{E}[R_t + G_{t+1}]\\\\\n",
    "&\\doteq \\mathbb{E} [R_{t+1} + \\gamma v_{\\pi}(S_{t+1})\\ |\\ S_t = s, A_t = a]\\\\\n",
    "&=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{split}\n",
    "\n",
    "__2__\n",
    "\\begin{split}\n",
    "Q^\\pi (s,a) &= max(\\mathbb{E}[R_t + G_{t+1}])\\\\\n",
    "&\\doteq \\mathbb{E} [R_{t} + max(\\gamma v_{\\pi}(S_{t+1})\\ |\\ S_t = s, A_t = a)]\\\\\n",
    "&=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma max_{a'} Q^{*}(s',a')]\n",
    "\\end{split}\n",
    "\n",
    "__3__\n",
    "\n",
    "Optimal Q:\n",
    "$$Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].$$\n",
    "Q from agent:\n",
    "$$Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]$$\n",
    "\n",
    "from above, it is obvious to get the loss function:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia-M8ewOrNfq"
   },
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QdnJE4r1rNf4"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = deque(maxlen = self.max_memory)\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        \n",
    "\n",
    "    def random_access(self):\n",
    "        return self.memory[np.random.randint(len(self.memory))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04QpebL6rNgy"
   },
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "A8swFowprNg2"
   },
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    agent.epsilon = 0.9\n",
    "    for e in range(epoch):\n",
    "        agent.epsilon = agent.epsilon * 0.9\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over,com = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 2 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "#         print(agent.epsilon)\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WJv6mVrrNha"
   },
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a5q63nDtrNhw"
   },
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        aa = np.argmax(self.model.predict(s.reshape(1,5,5,self.n_state)))\n",
    "        return aa\n",
    "\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state)) #16,5,5,2\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            s, n_s, a, r, game_over = self.memory.random_access()\n",
    "            \n",
    "            if game_over_:\n",
    "                target_q[i][a] = r\n",
    "            else:\n",
    "                input_states[i] = s\n",
    "                q = self.model.predict(n_s[np.newaxis,:])\n",
    "                target_q[i][a] = r + self.discount * np.max(q)\n",
    "\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "        return l\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        ####### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=32,input_shape = (5,5,self.n_state),activation=\"relu\"))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(4,activation=\"linear\"))        \n",
    "        model.compile(sgd(lr=lr, decay=1e-2, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1523446264530,
     "user": {
      "displayName": "Ryan Tian",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103527607988458266637"
     },
     "user_tz": -120
    },
    "id": "T0cq7XvorNiQ",
    "outputId": "228c6d49-3e5d-47d7-b0cb-653e1695de48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/030 | Loss 0.0277 | Win/lose count 11.5/15.0 (-3.5)\n",
      "Epoch 001/030 | Loss 0.0162 | Win/lose count 13.5/12.0 (1.5)\n",
      "Epoch 002/030 | Loss 0.0091 | Win/lose count 16.5/12.0 (4.5)\n",
      "Epoch 003/030 | Loss 0.0210 | Win/lose count 10.0/15.0 (-5.0)\n",
      "Epoch 004/030 | Loss 0.0103 | Win/lose count 14.5/23.0 (-8.5)\n",
      "Epoch 005/030 | Loss 0.0250 | Win/lose count 12.0/13.0 (-1.0)\n",
      "Epoch 006/030 | Loss 0.0146 | Win/lose count 9.5/12.0 (-2.5)\n",
      "Epoch 007/030 | Loss 0.0042 | Win/lose count 7.5/14.0 (-6.5)\n",
      "Epoch 008/030 | Loss 0.0181 | Win/lose count 9.0/19.0 (-10.0)\n",
      "Epoch 009/030 | Loss 0.0284 | Win/lose count 9.5/4.0 (5.5)\n",
      "Epoch 010/030 | Loss 0.0181 | Win/lose count 10.0/19.0 (-9.0)\n",
      "Epoch 011/030 | Loss 0.0182 | Win/lose count 14.0/10.0 (4.0)\n",
      "Epoch 012/030 | Loss 0.0232 | Win/lose count 7.0/21.0 (-14.0)\n",
      "Epoch 013/030 | Loss 0.0153 | Win/lose count 6.5/9.0 (-2.5)\n",
      "Epoch 014/030 | Loss 0.0405 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 015/030 | Loss 0.0166 | Win/lose count 8.5/7.0 (1.5)\n",
      "Epoch 016/030 | Loss 0.0185 | Win/lose count 6.5/5.0 (1.5)\n",
      "Epoch 017/030 | Loss 0.0010 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 018/030 | Loss 0.0173 | Win/lose count 8.0/8.0 (0.0)\n",
      "Epoch 019/030 | Loss 0.0032 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 020/030 | Loss 0.0010 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 021/030 | Loss 0.0027 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 022/030 | Loss 0.0027 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 023/030 | Loss 0.0110 | Win/lose count 10.0/4.0 (6.0)\n",
      "Epoch 024/030 | Loss 0.0032 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 025/030 | Loss 0.0116 | Win/lose count 9.0/3.0 (6.0)\n",
      "Epoch 026/030 | Loss 0.0010 | Win/lose count 10.0/13.0 (-3.0)\n",
      "Epoch 027/030 | Loss 0.0042 | Win/lose count 5.0/5.0 (0.0)\n",
      "Epoch 028/030 | Loss 0.0032 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 029/030 | Loss 0.0032 | Win/lose count 5.5/6.0 (-0.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=256, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, 30, prefix='fc_train')\n",
    "HTML(display_videos('fc_train20.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHIM4p4orNju"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vskHo9_-avY"
   },
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bjXXPdytrNkA"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        input_shape = (5,5, self.n_state)\n",
    "        model.add(Conv2D(64,(2,2), input_shape=input_shape))\n",
    "        model.add(Conv2D(32, (2,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 646950,
     "status": "error",
     "timestamp": 1523450088415,
     "user": {
      "displayName": "Ryan Tian",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103527607988458266637"
     },
     "user_tz": -120
    },
    "id": "EPFAjpqCrNkI",
    "outputId": "bd3147d7-e375-48e8-b7d0-1d09545e5efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/101 | Loss 0.0468 | Win/lose count 16.0/29.0 (-13.0)\n",
      "Epoch 001/101 | Loss 0.0030 | Win/lose count 10.0/11.0 (-1.0)\n",
      "Epoch 002/101 | Loss 0.0200 | Win/lose count 9.5/15.0 (-5.5)\n",
      "Epoch 003/101 | Loss 0.0291 | Win/lose count 7.0/8.0 (-1.0)\n",
      "Epoch 004/101 | Loss 0.0262 | Win/lose count 19.0/18.0 (1.0)\n",
      "Epoch 005/101 | Loss 0.0146 | Win/lose count 13.0/19.0 (-6.0)\n",
      "Epoch 006/101 | Loss 0.0220 | Win/lose count 8.5/7.0 (1.5)\n",
      "Epoch 007/101 | Loss 0.0262 | Win/lose count 21.5/13.0 (8.5)\n",
      "Epoch 008/101 | Loss 0.0146 | Win/lose count 4.5/6.0 (-1.5)\n",
      "Epoch 009/101 | Loss 0.0027 | Win/lose count 9.5/13.0 (-3.5)\n",
      "Epoch 010/101 | Loss 0.0024 | Win/lose count 6.5/12.0 (-5.5)\n",
      "Epoch 011/101 | Loss 0.0218 | Win/lose count 11.0/4.0 (7.0)\n",
      "Epoch 012/101 | Loss 0.0106 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 013/101 | Loss 0.0029 | Win/lose count 15.5/7.0 (8.5)\n",
      "Epoch 014/101 | Loss 0.0124 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 015/101 | Loss 0.0025 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 016/101 | Loss 0.0127 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 017/101 | Loss 0.0058 | Win/lose count 20.5/4.0 (16.5)\n",
      "Epoch 018/101 | Loss 0.0089 | Win/lose count 14.5/8.0 (6.5)\n",
      "Epoch 019/101 | Loss 0.0164 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 020/101 | Loss 0.0200 | Win/lose count 12.5/4.0 (8.5)\n",
      "Epoch 021/101 | Loss 0.0175 | Win/lose count 8.5/2.0 (6.5)\n",
      "Epoch 022/101 | Loss 0.0178 | Win/lose count 20.0/2.0 (18.0)\n",
      "Epoch 023/101 | Loss 0.0096 | Win/lose count 9.5/4.0 (5.5)\n",
      "Epoch 024/101 | Loss 0.0084 | Win/lose count 18.0/7.0 (11.0)\n",
      "Epoch 025/101 | Loss 0.0072 | Win/lose count 21.5/3.0 (18.5)\n",
      "Epoch 026/101 | Loss 0.0253 | Win/lose count 8.0/3.0 (5.0)\n",
      "Epoch 027/101 | Loss 0.0094 | Win/lose count 20.5/0 (20.5)\n",
      "Epoch 028/101 | Loss 0.0236 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 029/101 | Loss 0.0151 | Win/lose count 19.5/2.0 (17.5)\n",
      "Epoch 030/101 | Loss 0.0126 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 031/101 | Loss 0.0100 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 032/101 | Loss 0.0072 | Win/lose count 17.0/3.0 (14.0)\n",
      "Epoch 033/101 | Loss 0.0057 | Win/lose count 15.5/5.0 (10.5)\n",
      "Epoch 034/101 | Loss 0.0087 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 035/101 | Loss 0.0092 | Win/lose count 12.5/0 (12.5)\n",
      "Epoch 036/101 | Loss 0.0111 | Win/lose count 22.5/3.0 (19.5)\n",
      "Epoch 037/101 | Loss 0.0121 | Win/lose count 8.0/2.0 (6.0)\n",
      "Epoch 038/101 | Loss 0.0117 | Win/lose count 24.0/1.0 (23.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-f4d5d4ad64f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN_CNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cnn_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_train10.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-cd4228f19098>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(agent, env, epoch, prefix)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# Apply the reinforcement strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Save as a mp4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-3e06819fdf63>\u001b[0m in \u001b[0;36mreinforce\u001b[1;34m(self, s_, n_s_, a_, r_, game_over_)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0minput_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m#print(self.action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1027\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1800\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "env = Environment(grid_size=size, max_time=256, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.2, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,101,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pCQ57m5rNku"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the agent sometimes just trapped in a corner and cannot explore the whole map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1879
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31374,
     "status": "error",
     "timestamp": 1523450122637,
     "user": {
      "displayName": "Ryan Tian",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103527607988458266637"
     },
     "user_tz": -120
    },
    "id": "UdzMbhOJrNk2",
    "outputId": "14638746-30e4-4c93-e632-5ae2e3763fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 43.0/1.0. Average score (42.0)\n",
      "Win/lose count 43.5/4.0. Average score (40.75)\n",
      "Win/lose count 19.5/2.0. Average score (33.0)\n",
      "Win/lose count 6.0/0. Average score (26.25)\n",
      "Win/lose count 30.0/4.0. Average score (26.2)\n",
      "Win/lose count 8.5/0. Average score (23.25)\n",
      "Win/lose count 8.5/2.0. Average score (20.857142857142858)\n",
      "Win/lose count 23.5/3.0. Average score (20.8125)\n",
      "Win/lose count 8.0/2.0. Average score (19.166666666666668)\n",
      "Win/lose count 13.0/1.0. Average score (18.45)\n",
      "Win/lose count 22.5/1.0. Average score (18.727272727272727)\n",
      "\n",
      "Final score: 18.727272727272727\n",
      "Test of the FC\n",
      "Win/lose count 1.0/1.0. Average score (0.0)\n",
      "Win/lose count 2.0/2.0. Average score (0.0)\n",
      "Win/lose count 0.5/0. Average score (0.16666666666666666)\n",
      "Win/lose count 1.5/0. Average score (0.5)\n",
      "Win/lose count 1.5/1.0. Average score (0.5)\n",
      "Win/lose count 0.5/0. Average score (0.5)\n",
      "Win/lose count 2.5/0. Average score (0.7857142857142857)\n",
      "Win/lose count 1.5/0. Average score (0.875)\n",
      "Win/lose count 1.0/0. Average score (0.8888888888888888)\n",
      "Win/lose count 2.5/1.0. Average score (0.95)\n",
      "Win/lose count 0.5/0. Average score (0.9090909090909091)\n",
      "\n",
      "Final score: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=256,temperature=0.5)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "miebJNyarNlU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test0.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Hgmd0_0UrNmE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWEAeQXorNmS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkoJyBJyrNmS"
   },
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SxB9Dc3grNmU"
   },
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    train = True\n",
    "    agent.epsilon = 0.9\n",
    "    for e in range(epoch):\n",
    "        agent.epsilon = agent.epsilon * 0.9\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        com= False\n",
    "        while not game_over:\n",
    "            action = agent.act(state)\n",
    "            prev_state = state\n",
    "            state, reward, game_over,com = env.act(action, train)\n",
    "\n",
    "              # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "              # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "          # Save as a mp4\n",
    "            \n",
    "            if e % 10 == 0:\n",
    "                env.draw(prefix+str(e))\n",
    "            if com:\n",
    "                env.draw(prefix+str(e))\n",
    "\n",
    "          # Update stats\n",
    "            score += win-lose\n",
    "            \n",
    "        print(\"\\nEpoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {:.1f}/{:.1f} ({:.1f})\"\n",
    "                .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "    \n",
    "            \n",
    "        \n",
    "class EnvironmentExploring():\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size + 4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature        \n",
    "        \n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "        \n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16        \n",
    "        \n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "        \n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "    def act(self, action, train=False):\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        \n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        game_over = self.t > self.max_time\n",
    "        com = False\n",
    "        reward = 0\n",
    "        if train: \n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] += 0.1\n",
    "        \n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        if np.count_nonzero(self.board == 0.5) == 0:\n",
    "            game_over = True\n",
    "            reward += 30\n",
    "            com = True\n",
    "            print('eat it up')\n",
    "        self.board[self.x, self.y] = 0\n",
    "        \n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "        return state, reward, game_over,com\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "        \n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        \n",
    "        self.board[0:2,:]= 0\n",
    "        self.board[:,0:2] = 0\n",
    "        self.board[-2:, :] = 0\n",
    "        self.board[:, -2:] = 0\n",
    "        \n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "JYTlpW0TrNma",
    "outputId": "5d6550d4-063f-4e7a-d2ac-351e67f396b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 000/128 | Loss 0.0448 | Win/lose count 8.5/98.7 (-90.2)\n",
      "\n",
      "Epoch 001/128 | Loss 0.0538 | Win/lose count 15.0/74.0 (-59.0)\n",
      "\n",
      "Epoch 002/128 | Loss 0.0429 | Win/lose count 18.0/64.3 (-46.3)\n",
      "\n",
      "Epoch 003/128 | Loss 0.0429 | Win/lose count 16.0/76.1 (-60.1)\n",
      "\n",
      "Epoch 004/128 | Loss 0.0437 | Win/lose count 21.0/54.2 (-33.2)\n",
      "\n",
      "Epoch 005/128 | Loss 0.0743 | Win/lose count 24.0/43.8 (-19.8)\n",
      "\n",
      "Epoch 006/128 | Loss 0.0605 | Win/lose count 23.5/49.3 (-25.8)\n",
      "\n",
      "Epoch 007/128 | Loss 0.0491 | Win/lose count 20.0/53.1 (-33.1)\n",
      "\n",
      "Epoch 008/128 | Loss 0.0448 | Win/lose count 17.5/66.4 (-48.9)\n",
      "\n",
      "Epoch 009/128 | Loss 0.0362 | Win/lose count 18.5/56.0 (-37.5)\n",
      "\n",
      "Epoch 010/128 | Loss 0.0468 | Win/lose count 21.0/46.8 (-25.8)\n",
      "\n",
      "Epoch 011/128 | Loss 0.0252 | Win/lose count 25.5/35.1 (-9.6)\n",
      "\n",
      "Epoch 012/128 | Loss 0.0356 | Win/lose count 27.5/34.6 (-7.1)\n",
      "\n",
      "Epoch 013/128 | Loss 0.0586 | Win/lose count 20.5/48.6 (-28.1)\n",
      "\n",
      "Epoch 014/128 | Loss 0.0614 | Win/lose count 26.0/39.4 (-13.4)\n",
      "\n",
      "Epoch 015/128 | Loss 0.0358 | Win/lose count 25.5/35.8 (-10.3)\n",
      "eat it up\n",
      "\n",
      "Epoch 016/128 | Loss 0.0427 | Win/lose count 54.9/32.6 (22.3)\n",
      "\n",
      "Epoch 017/128 | Loss 0.0441 | Win/lose count 26.5/39.3 (-12.8)\n",
      "\n",
      "Epoch 018/128 | Loss 0.0349 | Win/lose count 22.5/36.2 (-13.7)\n",
      "\n",
      "Epoch 019/128 | Loss 0.0385 | Win/lose count 22.5/38.8 (-16.3)\n",
      "\n",
      "Epoch 020/128 | Loss 0.0562 | Win/lose count 22.0/94.1 (-72.1)\n",
      "\n",
      "Epoch 021/128 | Loss 0.0519 | Win/lose count 19.5/78.8 (-59.3)\n",
      "\n",
      "Epoch 022/128 | Loss 0.0622 | Win/lose count 26.0/67.0 (-41.0)\n",
      "\n",
      "Epoch 023/128 | Loss 0.0834 | Win/lose count 19.0/57.0 (-38.0)\n",
      "\n",
      "Epoch 024/128 | Loss 0.0598 | Win/lose count 24.5/59.1 (-34.6)\n",
      "\n",
      "Epoch 025/128 | Loss 0.0855 | Win/lose count 24.5/54.7 (-30.2)\n",
      "\n",
      "Epoch 026/128 | Loss 0.0977 | Win/lose count 20.0/66.3 (-46.3)\n",
      "\n",
      "Epoch 027/128 | Loss 0.0933 | Win/lose count 22.0/60.7 (-38.7)\n",
      "eat it up\n",
      "\n",
      "Epoch 028/128 | Loss 0.0738 | Win/lose count 61.0/52.0 (9.0)\n",
      "\n",
      "Epoch 029/128 | Loss 0.0614 | Win/lose count 19.5/56.8 (-37.3)\n",
      "\n",
      "Epoch 030/128 | Loss 0.0738 | Win/lose count 21.0/72.4 (-51.4)\n",
      "eat it up\n",
      "\n",
      "Epoch 031/128 | Loss 0.0539 | Win/lose count 52.9/31.4 (21.5)\n",
      "eat it up\n",
      "\n",
      "Epoch 032/128 | Loss 0.0633 | Win/lose count 54.8/32.2 (22.6)\n",
      "\n",
      "Epoch 033/128 | Loss 0.0618 | Win/lose count 26.5/66.1 (-39.6)\n",
      "\n",
      "Epoch 034/128 | Loss 0.0514 | Win/lose count 23.5/62.7 (-39.2)\n",
      "\n",
      "Epoch 035/128 | Loss 0.0952 | Win/lose count 22.5/61.6 (-39.1)\n",
      "\n",
      "Epoch 036/128 | Loss 0.0340 | Win/lose count 25.5/56.0 (-30.5)\n",
      "\n",
      "Epoch 037/128 | Loss 0.0873 | Win/lose count 22.5/122.4 (-99.9)\n",
      "eat it up\n",
      "\n",
      "Epoch 038/128 | Loss 0.0905 | Win/lose count 59.0/32.8 (26.2)\n",
      "\n",
      "Epoch 039/128 | Loss 0.1299 | Win/lose count 23.0/57.2 (-34.2)\n",
      "\n",
      "Epoch 040/128 | Loss 0.0576 | Win/lose count 21.0/69.9 (-48.9)\n",
      "\n",
      "Epoch 041/128 | Loss 0.0994 | Win/lose count 21.0/53.3 (-32.3)\n",
      "\n",
      "Epoch 042/128 | Loss 0.0828 | Win/lose count 19.5/52.8 (-33.3)\n",
      "\n",
      "Epoch 043/128 | Loss 0.0504 | Win/lose count 23.5/58.3 (-34.8)\n",
      "\n",
      "Epoch 044/128 | Loss 0.0634 | Win/lose count 17.0/139.6 (-122.6)\n",
      "\n",
      "Epoch 045/128 | Loss 0.1083 | Win/lose count 23.5/183.3 (-159.8)\n",
      "\n",
      "Epoch 046/128 | Loss 0.0511 | Win/lose count 29.5/60.0 (-30.5)\n",
      "\n",
      "Epoch 047/128 | Loss 0.0561 | Win/lose count 21.0/60.8 (-39.8)\n",
      "\n",
      "Epoch 048/128 | Loss 0.0970 | Win/lose count 23.0/41.3 (-18.3)\n",
      "\n",
      "Epoch 049/128 | Loss 0.0489 | Win/lose count 23.5/56.0 (-32.5)\n",
      "\n",
      "Epoch 050/128 | Loss 0.1111 | Win/lose count 16.5/193.0 (-176.5)\n",
      "\n",
      "Epoch 051/128 | Loss 0.0847 | Win/lose count 20.5/103.5 (-83.0)\n",
      "\n",
      "Epoch 052/128 | Loss 0.1351 | Win/lose count 20.0/97.0 (-77.0)\n",
      "\n",
      "Epoch 053/128 | Loss 0.1594 | Win/lose count 19.5/92.8 (-73.3)\n",
      "\n",
      "Epoch 054/128 | Loss 0.0436 | Win/lose count 25.0/60.5 (-35.5)\n",
      "\n",
      "Epoch 055/128 | Loss 0.1546 | Win/lose count 29.5/58.9 (-29.4)\n",
      "\n",
      "Epoch 056/128 | Loss 0.0506 | Win/lose count 14.5/76.8 (-62.3)\n",
      "\n",
      "Epoch 057/128 | Loss 0.0429 | Win/lose count 24.5/64.4 (-39.9)\n",
      "\n",
      "Epoch 058/128 | Loss 0.1612 | Win/lose count 26.5/52.7 (-26.2)\n",
      "\n",
      "Epoch 059/128 | Loss 0.1377 | Win/lose count 26.0/123.2 (-97.2)\n",
      "\n",
      "Epoch 060/128 | Loss 0.1129 | Win/lose count 26.0/130.5 (-104.5)\n",
      "\n",
      "Epoch 061/128 | Loss 0.0720 | Win/lose count 19.0/120.4 (-101.4)\n",
      "\n",
      "Epoch 062/128 | Loss 0.1333 | Win/lose count 21.0/58.2 (-37.2)\n",
      "\n",
      "Epoch 063/128 | Loss 0.1312 | Win/lose count 24.5/78.2 (-53.7)\n",
      "\n",
      "Epoch 064/128 | Loss 0.0939 | Win/lose count 22.5/162.1 (-139.6)\n",
      "\n",
      "Epoch 065/128 | Loss 0.2134 | Win/lose count 19.0/158.2 (-139.2)\n",
      "\n",
      "Epoch 066/128 | Loss 0.1531 | Win/lose count 20.0/190.9 (-170.9)\n",
      "\n",
      "Epoch 067/128 | Loss 0.1465 | Win/lose count 24.0/95.3 (-71.3)\n",
      "\n",
      "Epoch 068/128 | Loss 0.0619 | Win/lose count 17.5/107.6 (-90.1)\n",
      "\n",
      "Epoch 069/128 | Loss 0.1726 | Win/lose count 27.0/62.2 (-35.2)\n",
      "\n",
      "Epoch 070/128 | Loss 0.2445 | Win/lose count 24.5/150.6 (-126.1)\n",
      "\n",
      "Epoch 071/128 | Loss 0.2386 | Win/lose count 23.0/206.1 (-183.1)\n",
      "\n",
      "Epoch 072/128 | Loss 0.1876 | Win/lose count 24.5/72.5 (-48.0)\n",
      "\n",
      "Epoch 073/128 | Loss 0.1581 | Win/lose count 29.0/71.9 (-42.9)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b737b22a487b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironmentExploring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN_CNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_explore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cnn_train_explore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_train_explore10.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'random1.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-dd803af5fe03>\u001b[0m in \u001b[0;36mtrain_explore\u001b[1;34m(agent, env, epoch, prefix)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m               \u001b[1;31m# Apply the reinforcement strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m           \u001b[1;31m# Save as a mp4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3e06819fdf63>\u001b[0m in \u001b[0;36mreinforce\u001b[1;34m(self, s_, n_s_, a_, r_, game_over_)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0minput_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m#print(self.action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1027\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1800\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1295\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "# Training\n",
    "\n",
    "env = EnvironmentExploring(grid_size=size, max_time=300, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.01, memory_size=2500, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, 128, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))\n",
    "HTML(display_videos('random1.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9471,
     "status": "ok",
     "timestamp": 1523465337557,
     "user": {
      "displayName": "Ryan Tian",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103527607988458266637"
     },
     "user_tz": -120
    },
    "id": "dQPcdO69G8wn",
    "outputId": "f9f5d5e0-edf0-4989-de15-8e8a22070875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 18.5/5.0. Average score (13.5)\n",
      "Win/lose count 17.5/5.0. Average score (13.0)\n",
      "Win/lose count 17.5/3.0. Average score (13.5)\n",
      "Win/lose count 18.0/2.0. Average score (14.125)\n",
      "Win/lose count 20.5/1.0. Average score (15.2)\n",
      "Win/lose count 16.0/2.0. Average score (15.0)\n",
      "Win/lose count 21.5/6.0. Average score (15.071428571428571)\n",
      "Win/lose count 18.5/1.0. Average score (15.375)\n",
      "Win/lose count 21.5/2.0. Average score (15.833333333333334)\n",
      "Win/lose count 20.0/5.0. Average score (15.75)\n",
      "Win/lose count 19.5/3.0. Average score (15.818181818181818)\n",
      "\n",
      "Final score: 15.818181818181818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "env = EnvironmentExploring(grid_size=size, max_time=100, temperature=0.3)\n",
    "agent1 = DQN_CNN(size, lr=.1, epsilon = 0.01, memory_size=2500, batch_size = 64,n_state=3)\n",
    "agent1.load(name_weights='cnn_train_exploremodel.h5',name_model='cnn_train_exploremodel.json')\n",
    "test(agent1,env,11,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TXy7iF4TrNnG"
   },
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S58IgoqorNnG"
   },
   "source": [
    "I mortified the enviornment such that if all the cheese are eated the game is over and give it a big reward. Meanwhile, I make the max time longer to make the agent to achieve the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WuFtNbknrNnI"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentExploring2():\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size + 4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature        \n",
    "        \n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "        \n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16        \n",
    "        \n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "        pass\n",
    "        \n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "    def act(self, action, train=False):\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        \n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        game_over = self.t > self.max_time\n",
    "        reward = 0\n",
    "        if train: \n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = self.malus_position[self.x, self.y]*1.001\n",
    "        self.malus_position[self.x, self.y] += 0.1\n",
    "        \n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        \n",
    "        self.board[self.x, self.y] = 0\n",
    "        if np.count_nonzero(self.board == 0.5) == 0:\n",
    "            game_over = True\n",
    "            reward += 30\n",
    "            print('completed')\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "        return state, reward, game_over    \n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "        \n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        \n",
    "        self.board[0:2,:]= 0\n",
    "        self.board[:,0:2] = 0\n",
    "        self.board[-2:, :] = 0\n",
    "        self.board[:, -2:] = 0\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 000/128 | Loss 0.0790 | Win/lose count 29.0/173.7 (-144.7)\n",
      "\n",
      "Epoch 001/128 | Loss 0.0784 | Win/lose count 30.0/182.4 (-152.4)\n",
      "\n",
      "Epoch 002/128 | Loss 0.0449 | Win/lose count 37.5/135.1 (-97.6)\n",
      "\n",
      "Epoch 003/128 | Loss 0.0561 | Win/lose count 28.0/150.4 (-122.4)\n",
      "\n",
      "Epoch 004/128 | Loss 0.0461 | Win/lose count 36.5/142.9 (-106.4)\n",
      "\n",
      "Epoch 005/128 | Loss 0.0584 | Win/lose count 39.5/109.4 (-69.9)\n",
      "\n",
      "Epoch 006/128 | Loss 0.0487 | Win/lose count 44.0/132.7 (-88.7)\n",
      "\n",
      "Epoch 007/128 | Loss 0.0605 | Win/lose count 39.5/118.7 (-79.2)\n",
      "\n",
      "Epoch 008/128 | Loss 0.0452 | Win/lose count 38.5/116.0 (-77.5)\n",
      "\n",
      "Epoch 009/128 | Loss 0.0444 | Win/lose count 43.5/104.4 (-60.9)\n",
      "\n",
      "Epoch 010/128 | Loss 0.0428 | Win/lose count 45.5/102.1 (-56.6)\n",
      "\n",
      "Epoch 011/128 | Loss 0.0547 | Win/lose count 36.5/133.1 (-96.6)\n",
      "\n",
      "Epoch 012/128 | Loss 0.0730 | Win/lose count 38.5/146.1 (-107.6)\n",
      "\n",
      "Epoch 013/128 | Loss 0.0526 | Win/lose count 37.0/136.6 (-99.6)\n",
      "\n",
      "Epoch 014/128 | Loss 0.0549 | Win/lose count 39.0/156.5 (-117.5)\n",
      "\n",
      "Epoch 015/128 | Loss 0.0694 | Win/lose count 42.0/166.9 (-124.9)\n",
      "\n",
      "Epoch 016/128 | Loss 0.0749 | Win/lose count 38.5/147.8 (-109.3)\n",
      "\n",
      "Epoch 017/128 | Loss 0.0554 | Win/lose count 42.5/167.9 (-125.4)\n",
      "\n",
      "Epoch 018/128 | Loss 0.0631 | Win/lose count 33.5/153.3 (-119.8)\n",
      "\n",
      "Epoch 019/128 | Loss 0.0771 | Win/lose count 39.0/191.3 (-152.3)\n",
      "\n",
      "Epoch 020/128 | Loss 0.0633 | Win/lose count 44.5/161.2 (-116.7)\n",
      "\n",
      "Epoch 021/128 | Loss 0.0923 | Win/lose count 44.0/179.4 (-135.4)\n",
      "\n",
      "Epoch 022/128 | Loss 0.0926 | Win/lose count 39.5/168.1 (-128.6)\n",
      "\n",
      "Epoch 023/128 | Loss 0.0695 | Win/lose count 41.0/230.0 (-189.0)\n",
      "\n",
      "Epoch 024/128 | Loss 0.1770 | Win/lose count 46.0/289.5 (-243.5)\n",
      "\n",
      "Epoch 025/128 | Loss 0.1350 | Win/lose count 42.0/199.1 (-157.1)\n",
      "\n",
      "Epoch 026/128 | Loss 0.1200 | Win/lose count 38.0/193.2 (-155.2)\n",
      "\n",
      "Epoch 027/128 | Loss 0.1344 | Win/lose count 40.0/194.8 (-154.8)\n",
      "\n",
      "Epoch 028/128 | Loss 0.1219 | Win/lose count 39.0/221.8 (-182.8)\n",
      "\n",
      "Epoch 029/128 | Loss 0.1227 | Win/lose count 43.5/194.7 (-151.2)\n",
      "\n",
      "Epoch 030/128 | Loss 0.0669 | Win/lose count 30.0/275.7 (-245.7)\n",
      "\n",
      "Epoch 031/128 | Loss 0.0793 | Win/lose count 42.5/227.1 (-184.6)\n",
      "\n",
      "Epoch 032/128 | Loss 0.1275 | Win/lose count 38.5/281.7 (-243.2)\n",
      "\n",
      "Epoch 033/128 | Loss 0.1471 | Win/lose count 41.0/225.3 (-184.3)\n",
      "\n",
      "Epoch 034/128 | Loss 0.0798 | Win/lose count 41.0/178.3 (-137.3)\n",
      "\n",
      "Epoch 035/128 | Loss 0.1054 | Win/lose count 37.0/203.0 (-166.0)\n",
      "\n",
      "Epoch 036/128 | Loss 0.0897 | Win/lose count 36.5/191.1 (-154.6)\n",
      "\n",
      "Epoch 037/128 | Loss 0.1206 | Win/lose count 35.0/353.2 (-318.2)\n",
      "\n",
      "Epoch 038/128 | Loss 0.1082 | Win/lose count 30.0/282.1 (-252.1)\n",
      "\n",
      "Epoch 039/128 | Loss 0.1380 | Win/lose count 34.5/189.5 (-155.0)\n",
      "\n",
      "Epoch 040/128 | Loss 0.1487 | Win/lose count 40.5/198.6 (-158.1)\n",
      "\n",
      "Epoch 041/128 | Loss 0.1333 | Win/lose count 31.5/194.3 (-162.8)\n",
      "\n",
      "Epoch 042/128 | Loss 0.0961 | Win/lose count 40.5/182.4 (-141.9)\n",
      "\n",
      "Epoch 043/128 | Loss 0.1524 | Win/lose count 48.0/239.0 (-191.0)\n",
      "\n",
      "Epoch 044/128 | Loss 0.0729 | Win/lose count 35.5/201.8 (-166.3)\n",
      "\n",
      "Epoch 045/128 | Loss 0.1755 | Win/lose count 36.0/253.5 (-217.5)\n",
      "\n",
      "Epoch 046/128 | Loss 0.2052 | Win/lose count 37.5/266.6 (-229.1)\n",
      "\n",
      "Epoch 047/128 | Loss 0.2577 | Win/lose count 39.0/211.2 (-172.2)\n",
      "\n",
      "Epoch 048/128 | Loss 0.1385 | Win/lose count 35.5/267.4 (-231.9)\n",
      "\n",
      "Epoch 049/128 | Loss 0.1503 | Win/lose count 44.5/254.8 (-210.3)\n",
      "\n",
      "Epoch 050/128 | Loss 0.1889 | Win/lose count 34.5/370.9 (-336.4)\n",
      "\n",
      "Epoch 051/128 | Loss 0.2677 | Win/lose count 37.5/203.3 (-165.8)\n",
      "\n",
      "Epoch 052/128 | Loss 0.2905 | Win/lose count 37.0/221.8 (-184.8)\n",
      "\n",
      "Epoch 053/128 | Loss 0.3778 | Win/lose count 22.5/616.5 (-594.0)\n",
      "\n",
      "Epoch 054/128 | Loss 0.3406 | Win/lose count 37.5/397.9 (-360.4)\n",
      "\n",
      "Epoch 055/128 | Loss 0.2548 | Win/lose count 37.0/389.7 (-352.7)\n",
      "\n",
      "Epoch 056/128 | Loss 0.4870 | Win/lose count 26.5/274.4 (-247.9)\n",
      "\n",
      "Epoch 057/128 | Loss 0.4329 | Win/lose count 35.0/269.7 (-234.7)\n",
      "\n",
      "Epoch 058/128 | Loss 0.2348 | Win/lose count 39.0/165.3 (-126.3)\n",
      "\n",
      "Epoch 059/128 | Loss 0.2645 | Win/lose count 39.0/314.3 (-275.3)\n",
      "\n",
      "Epoch 060/128 | Loss 0.1984 | Win/lose count 35.5/245.6 (-210.1)\n",
      "\n",
      "Epoch 061/128 | Loss 0.2600 | Win/lose count 37.0/261.4 (-224.4)\n",
      "\n",
      "Epoch 062/128 | Loss 0.1888 | Win/lose count 41.0/247.0 (-206.0)\n",
      "\n",
      "Epoch 063/128 | Loss 0.2441 | Win/lose count 37.0/407.7 (-370.7)\n",
      "\n",
      "Epoch 064/128 | Loss 0.3550 | Win/lose count 37.5/316.8 (-279.3)\n",
      "\n",
      "Epoch 065/128 | Loss 0.3728 | Win/lose count 41.0/401.3 (-360.3)\n",
      "\n",
      "Epoch 066/128 | Loss 0.2979 | Win/lose count 35.5/532.6 (-497.1)\n",
      "\n",
      "Epoch 067/128 | Loss 0.5053 | Win/lose count 40.5/431.0 (-390.5)\n",
      "\n",
      "Epoch 068/128 | Loss 0.4334 | Win/lose count 37.5/428.7 (-391.2)\n",
      "\n",
      "Epoch 069/128 | Loss 0.5258 | Win/lose count 42.5/462.3 (-419.8)\n",
      "\n",
      "Epoch 070/128 | Loss 0.5151 | Win/lose count 41.0/333.4 (-292.4)\n",
      "\n",
      "Epoch 071/128 | Loss 0.4333 | Win/lose count 41.5/298.1 (-256.6)\n",
      "\n",
      "Epoch 072/128 | Loss 0.2797 | Win/lose count 43.5/264.8 (-221.3)\n",
      "\n",
      "Epoch 073/128 | Loss 0.2531 | Win/lose count 38.5/262.9 (-224.4)\n",
      "\n",
      "Epoch 074/128 | Loss 0.2482 | Win/lose count 29.5/269.0 (-239.5)\n",
      "\n",
      "Epoch 075/128 | Loss 0.1792 | Win/lose count 38.0/499.6 (-461.6)\n",
      "\n",
      "Epoch 076/128 | Loss 0.3144 | Win/lose count 36.5/288.8 (-252.3)\n",
      "\n",
      "Epoch 077/128 | Loss 0.1589 | Win/lose count 43.0/267.1 (-224.1)\n",
      "\n",
      "Epoch 078/128 | Loss 0.4849 | Win/lose count 33.0/462.6 (-429.6)\n",
      "\n",
      "Epoch 079/128 | Loss 0.3523 | Win/lose count 36.5/226.9 (-190.4)\n",
      "\n",
      "Epoch 080/128 | Loss 0.2578 | Win/lose count 37.0/348.1 (-311.1)\n",
      "\n",
      "Epoch 081/128 | Loss 0.2734 | Win/lose count 33.0/417.0 (-384.0)\n",
      "\n",
      "Epoch 082/128 | Loss 0.3523 | Win/lose count 37.5/374.9 (-337.4)\n",
      "\n",
      "Epoch 083/128 | Loss 0.2703 | Win/lose count 30.0/522.3 (-492.3)\n",
      "\n",
      "Epoch 084/128 | Loss 0.4737 | Win/lose count 42.5/441.6 (-399.1)\n",
      "\n",
      "Epoch 085/128 | Loss 0.1988 | Win/lose count 32.5/450.2 (-417.7)\n",
      "\n",
      "Epoch 086/128 | Loss 0.3821 | Win/lose count 37.0/232.6 (-195.6)\n",
      "\n",
      "Epoch 087/128 | Loss 0.3146 | Win/lose count 37.0/449.7 (-412.7)\n",
      "\n",
      "Epoch 088/128 | Loss 0.3880 | Win/lose count 37.0/225.6 (-188.6)\n",
      "\n",
      "Epoch 089/128 | Loss 0.1930 | Win/lose count 32.0/284.5 (-252.5)\n",
      "\n",
      "Epoch 090/128 | Loss 0.1950 | Win/lose count 25.5/305.4 (-279.9)\n",
      "\n",
      "Epoch 091/128 | Loss 0.2263 | Win/lose count 22.5/487.8 (-465.3)\n",
      "\n",
      "Epoch 092/128 | Loss 0.1897 | Win/lose count 36.0/225.8 (-189.8)\n",
      "\n",
      "Epoch 093/128 | Loss 0.3225 | Win/lose count 34.0/1147.0 (-1113.0)\n",
      "\n",
      "Epoch 094/128 | Loss 0.3304 | Win/lose count 37.5/283.3 (-245.8)\n",
      "\n",
      "Epoch 095/128 | Loss 0.2591 | Win/lose count 44.0/285.3 (-241.3)\n",
      "\n",
      "Epoch 096/128 | Loss 0.2086 | Win/lose count 38.0/296.1 (-258.1)\n",
      "\n",
      "Epoch 097/128 | Loss 0.1925 | Win/lose count 37.5/204.4 (-166.9)\n",
      "\n",
      "Epoch 098/128 | Loss 0.2412 | Win/lose count 40.0/224.5 (-184.5)\n",
      "\n",
      "Epoch 099/128 | Loss 0.1958 | Win/lose count 41.0/208.0 (-167.0)\n",
      "\n",
      "Epoch 100/128 | Loss 0.1248 | Win/lose count 44.5/283.7 (-239.2)\n",
      "\n",
      "Epoch 101/128 | Loss 0.2355 | Win/lose count 40.0/382.2 (-342.2)\n",
      "\n",
      "Epoch 102/128 | Loss 0.1984 | Win/lose count 39.5/204.9 (-165.4)\n",
      "\n",
      "Epoch 103/128 | Loss 0.2495 | Win/lose count 41.5/260.3 (-218.8)\n",
      "\n",
      "Epoch 104/128 | Loss 0.2703 | Win/lose count 41.0/201.1 (-160.1)\n",
      "\n",
      "Epoch 105/128 | Loss 0.1572 | Win/lose count 37.5/303.3 (-265.8)\n",
      "\n",
      "Epoch 106/128 | Loss 0.1384 | Win/lose count 31.0/256.2 (-225.2)\n",
      "\n",
      "Epoch 107/128 | Loss 0.1778 | Win/lose count 44.5/174.6 (-130.1)\n",
      "\n",
      "Epoch 108/128 | Loss 0.1188 | Win/lose count 31.0/442.5 (-411.5)\n",
      "\n",
      "Epoch 109/128 | Loss 0.1921 | Win/lose count 39.0/216.8 (-177.8)\n",
      "\n",
      "Epoch 110/128 | Loss 0.1653 | Win/lose count 38.0/267.3 (-229.3)\n",
      "\n",
      "Epoch 111/128 | Loss 0.2230 | Win/lose count 30.5/228.1 (-197.6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-737ba6638781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironmentExploring2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0magent2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN_CNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_explore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cnn2_train_explore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c683ae089bc4>\u001b[0m in \u001b[0;36mtrain_explore\u001b[1;34m(agent, env, epoch, prefix)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m               \u001b[1;31m# Apply the reinforcement strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m           \u001b[1;31m# Save as a mp4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-3e06819fdf63>\u001b[0m in \u001b[0;36mreinforce\u001b[1;34m(self, s_, n_s_, a_, r_, game_over_)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0minput_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m#print(self.action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1027\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1800\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\env\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "env2 = EnvironmentExploring2(grid_size=size, max_time=512, temperature=0.5)\n",
    "agent2 = DQN_CNN(size, lr=.1, epsilon = 0.01, memory_size=2500, batch_size = 64,n_state=3)\n",
    "train_explore(agent2, env2, 128, prefix='cnn2_train_explore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 38.0/15.0. Average score (23.0)\n",
      "Win/lose count 31.0/10.0. Average score (22.0)\n",
      "Win/lose count 34.0/25.0. Average score (17.666666666666668)\n",
      "Win/lose count 46.0/11.0. Average score (22.0)\n",
      "Win/lose count 38.0/28.0. Average score (19.6)\n",
      "Win/lose count 44.5/31.0. Average score (18.583333333333332)\n",
      "Win/lose count 35.0/20.0. Average score (18.071428571428573)\n",
      "Win/lose count 37.0/18.0. Average score (18.1875)\n",
      "Win/lose count 39.0/17.0. Average score (18.61111111111111)\n",
      "Win/lose count 41.0/18.0. Average score (19.05)\n",
      "Win/lose count 38.5/16.0. Average score (19.363636363636363)\n",
      "\n",
      "Final score: 19.363636363636363\n"
     ]
    }
   ],
   "source": [
    "# from keras.layers import Flatten\n",
    "env3 = EnvironmentExploring2(grid_size=size, max_time=1024, temperature=0.5)\n",
    "# agent1 = DQN_CNN(size, lr=.1, epsilon = 0.01, memory_size=2500, batch_size = 64,n_state=3)\n",
    "# agent1.load(name_weights='cnn_train_exploremodel.h5',name_model='cnn_train_exploremodel.json')\n",
    "test(agent,env3,11,prefix='cnn_test_explore')\n",
    "# HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(agent,env,epochs,prefix=''):\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        ##### FILL IN HERE\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "        # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over,com = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "            # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "            # Update stats\n",
    "        score = score + win-lose\n",
    "            \n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('\\nFinal score: '+str(score/epochs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat it up\n",
      "Win/lose count 43.5/10.0. Average score (33.5)\n",
      "Win/lose count 15.5/10.0. Average score (19.5)\n",
      "Win/lose count 13.0/5.0. Average score (15.666666666666666)\n",
      "Win/lose count 12.5/11.0. Average score (12.125)\n",
      "Win/lose count 16.0/7.0. Average score (11.5)\n",
      "Win/lose count 11.0/11.0. Average score (9.583333333333334)\n",
      "Win/lose count 13.5/6.0. Average score (9.285714285714286)\n",
      "Win/lose count 10.5/14.0. Average score (7.6875)\n",
      "Win/lose count 13.0/3.0. Average score (7.944444444444445)\n",
      "Win/lose count 19.0/6.0. Average score (8.45)\n",
      "Win/lose count 16.0/7.0. Average score (8.5)\n",
      "Win/lose count 15.5/8.0. Average score (8.416666666666666)\n",
      "\n",
      "Final score: 8.416666666666666\n"
     ]
    }
   ],
   "source": [
    "env3 = EnvironmentExploring(grid_size=13, max_time=360, temperature=0.2)\n",
    "agent1 = DQN_CNN(size, lr=.1, epsilon = 0.01, memory_size=2500, batch_size = 64,n_state=3)\n",
    "agent1.load(name_weights='cnn_train_exploremodel.h5',name_model='cnn_train_exploremodel.json')\n",
    "test1(agent1,env3,12,prefix='cnn_test_explorexx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test_explorexx0.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test_explorexx2.mp4'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "DQN_project_MVA.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
